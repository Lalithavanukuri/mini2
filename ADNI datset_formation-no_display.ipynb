{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ff9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from h5py) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd6cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Test Data\n",
      "  Dataset: x_test\n",
      "  Dataset: y_test\n",
      "Group: Train Data\n",
      "  Dataset: x_train\n",
      "  Dataset: y_train\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "hdf5_file = h5py.File(r'ADNI_enhanced(1).h5')\n",
    "\n",
    "# List the groups and datasets in the file\n",
    "for group in hdf5_file.keys():\n",
    "    print(f\"Group: {group}\")\n",
    "    for dataset in hdf5_file[group].keys():\n",
    "        print(f\"  Dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3132ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access image dataset\n",
    "image_dataset = hdf5_file['Train Data/x_train']  # Update with actual group and dataset names\n",
    "\n",
    "# Convert dataset to a NumPy array\n",
    "images_array = image_dataset[()]\n",
    "\n",
    "# Process the images in images_array as needed\n",
    "# For example, you can save the images as image files, display them, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8d8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86fdd07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Test Data, Data Type: float32\n",
      "Group: Train Data, Data Type: float32\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "hdf5_file = h5py.File('ADNI_enhanced(1).h5', 'r')\n",
    "\n",
    "# List of group names\n",
    "group_names = ['Test Data', 'Train Data']\n",
    "\n",
    "# Loop through each group\n",
    "for group_name in group_names:\n",
    "    group = hdf5_file[group_name]\n",
    "\n",
    "    if group_name == 'Test Data':\n",
    "        input_images = group['x_test']\n",
    "    elif group_name == 'Train Data':\n",
    "        input_images = group['x_train']\n",
    "\n",
    "    # Check the data type of the images\n",
    "    data_type = input_images.dtype\n",
    "\n",
    "    # Print the data type to determine the format\n",
    "    print(f\"Group: {group_name}, Data Type: {data_type}\")\n",
    "\n",
    "# Close the HDF5 file when done\n",
    "hdf5_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d60fd42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in testX: 105\n",
      "Number of images in trainX: 940\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "hdf5_file = h5py.File('ADNI_enhanced(1).h5', 'r')  # Replace with your actual file path\n",
    "\n",
    "# Get the shapes of datasets\n",
    "test_x_shape = hdf5_file['Test Data']['x_test'].shape\n",
    "test_y_shape = hdf5_file['Test Data']['y_test'].shape\n",
    "\n",
    "train_x_shape = hdf5_file['Train Data']['x_train'].shape\n",
    "train_y_shape = hdf5_file['Train Data']['y_train'].shape\n",
    "\n",
    "\n",
    "\n",
    "# Get the number of images in each dataset\n",
    "num_test_images = test_x_shape[0]\n",
    "num_train_images = train_x_shape[0]\n",
    "#num_val_images = val_x_shape[0]\n",
    "\n",
    "# Close the HDF5 file when done\n",
    "hdf5_file.close()\n",
    "\n",
    "print(f\"Number of images in testX: {num_test_images}\")\n",
    "print(f\"Number of images in trainX: {num_train_images}\")\n",
    "#print(f\"Number of images in valX: {num_val_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dd6d6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in testY:\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "hdf5_file = h5py.File('ADNI_enhanced(1).h5', 'r')  # Replace with your actual file path\n",
    "\n",
    "# Access the testY dataset\n",
    "test_y_dataset = hdf5_file['Test Data']['y_test']\n",
    "\n",
    "# Convert the dataset to a NumPy array\n",
    "test_y_array = test_y_dataset[()]\n",
    "\n",
    "# Get unique labels\n",
    "unique_labels = set(test_y_array)\n",
    "\n",
    "# Close the HDF5 file when done\n",
    "hdf5_file.close()\n",
    "\n",
    "# Print the unique labels\n",
    "print(\"Unique labels in testY:\")\n",
    "for label in unique_labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef6b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in testY:\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGroup: Test Data\\n  Dataset: testX\\n  Dataset: testY\\nGroup: Train Data\\n  Dataset: trainX\\n  Dataset: trainY\\nGroup: Validation Data\\n  Dataset: valX\\n  Dataset: valY\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "hdf5_file = h5py.File('ADNI_enhanced(1).h5', 'r')  # Replace with your actual file path\n",
    "\n",
    "# Access the testY dataset\n",
    "test_y_dataset = hdf5_file['Train Data']['y_train']\n",
    "\n",
    "# Convert the dataset to a NumPy array\n",
    "test_y_array = test_y_dataset[()]\n",
    "\n",
    "# Get unique labels\n",
    "unique_labels = set(test_y_array)\n",
    "\n",
    "# Close the HDF5 file when done\n",
    "hdf5_file.close()\n",
    "\n",
    "# Print the unique labels\n",
    "print(\"Unique labels in testY:\")\n",
    "for label in unique_labels:\n",
    "    print(label)\n",
    "\n",
    "\"\"\"\n",
    "Group: Test Data\n",
    "  Dataset: testX\n",
    "  Dataset: testY\n",
    "Group: Train Data\n",
    "  Dataset: trainX\n",
    "  Dataset: trainY\n",
    "Group: Validation Data\n",
    "  Dataset: valX\n",
    "  Dataset: valY\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e8b5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Open the HDF5 file\n",
    "hdf5_file = h5py.File('ADNI_enhanced(1).h5', 'r')\n",
    "\n",
    "# Define the output directory where images will be saved\n",
    "output_dir = 'ADNI_images'  # Change this to your desired output directory\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each group\n",
    "group_names = ['Test Data', 'Train Data']\n",
    "\n",
    "for group_name in group_names:\n",
    "    group = hdf5_file[group_name]\n",
    "\n",
    "    if group_name == 'Test Data':\n",
    "        output_group_dir = os.path.join(output_dir, 'test')\n",
    "    elif group_name == 'Train Data':\n",
    "        output_group_dir = os.path.join(output_dir, 'train')\n",
    "\n",
    "    os.makedirs(output_group_dir, exist_ok=True)\n",
    "\n",
    "    input_images = group['x_test' if group_name == 'Test Data' else 'x_train']\n",
    "    labels = group['y_test' if group_name == 'Test Data' else 'y_train']\n",
    "\n",
    "    # Convert datasets to NumPy arrays\n",
    "    images_array = input_images[()]\n",
    "    labels_array = labels[()]\n",
    "\n",
    "    # Loop through images in the dataset\n",
    "    for i in range(images_array.shape[0]):\n",
    "        image_data = images_array[i]\n",
    "        label = labels_array[i]\n",
    "\n",
    "        # Create a subfolder for the class label\n",
    "        class_dir = os.path.join(output_group_dir, str(label))\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # Reshape the image data to a valid shape\n",
    "        image_data = image_data.reshape(image_data.shape[0], image_data.shape[1])\n",
    "\n",
    "        # Normalize the pixel values to the range [0, 255]\n",
    "        image_data = (image_data - np.min(image_data)) / (np.max(image_data) - np.min(image_data)) * 255\n",
    "\n",
    "        # Convert the data to a uint8 array\n",
    "        image_data = image_data.astype(np.uint8)\n",
    "\n",
    "        # Create a Pillow (PIL) image\n",
    "        image = Image.fromarray(image_data)\n",
    "\n",
    "        # Save the image as a PNG in the class-specific subfolder\n",
    "        image_filename = os.path.join(class_dir, f'{i}.png')\n",
    "        image.save(image_filename)\n",
    "\n",
    "# Close the HDF5 file when done\n",
    "hdf5_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
